# MCP AI Tools Server

A Model Context Protocol (MCP) server that hosts multiple AI tools with routing, tool loading, and JSON schema validation. This server provides a flexible framework for deploying and managing AI-powered tools through a RESTful API.

## üåü Features

- **Dynamic Tool Loading**: Automatically loads and registers tools from the `/tools` directory
- **JSON Schema Validation**: Validates both input and output using JSON schemas
- **RESTful API**: Simple and intuitive REST API for tool discovery and execution
- **Extensible Architecture**: Easy to add new tools by following a simple pattern
- **Production Ready**: Includes health checks, error handling, and graceful shutdown
- **Deployment Ready**: Configured for deployment on Vercel, Render, or any Node.js hosting

## üìÅ Project Structure

```
.
‚îú‚îÄ‚îÄ server/              # Server implementation
‚îÇ   ‚îú‚îÄ‚îÄ index.js         # Main server with routing
‚îÇ   ‚îú‚îÄ‚îÄ tool-loader.js   # Dynamic tool loading
‚îÇ   ‚îî‚îÄ‚îÄ schema-validator.js  # JSON schema validation
‚îú‚îÄ‚îÄ tools/               # AI tool implementations
‚îÇ   ‚îú‚îÄ‚îÄ action_impact_model.js
‚îÇ   ‚îî‚îÄ‚îÄ category_level_model.js
‚îú‚îÄ‚îÄ schemas/             # JSON schemas for validation
‚îÇ   ‚îú‚îÄ‚îÄ tool-input.schema.json
‚îÇ   ‚îî‚îÄ‚îÄ tool-output.schema.json
‚îú‚îÄ‚îÄ config/              # Configuration files
‚îÇ   ‚îî‚îÄ‚îÄ server.config.js
‚îú‚îÄ‚îÄ tests/               # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ tool-loader.test.js
‚îÇ   ‚îú‚îÄ‚îÄ schema-validator.test.js
‚îÇ   ‚îî‚îÄ‚îÄ tools.test.js
‚îî‚îÄ‚îÄ package.json
```

## üöÄ Quick Start

### Prerequisites

- Node.js 18.0.0 or higher
- npm or yarn

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd MVP-Product-Workspace
```

2. Install dependencies:
```bash
npm install
```

3. Start the server:
```bash
npm start
```

The server will start on `http://localhost:3000` by default.

## üõ†Ô∏è Development

### Running in Development Mode

Use Node.js watch mode for automatic restarts on file changes:

```bash
npm run dev
```

### Running Tests

Execute the test suite:

```bash
npm test
```

## üìö API Documentation

### Base URL
```
http://localhost:3000
```

### Endpoints

#### 1. API Information
```
GET /
```
Returns server information and available endpoints.

**Response:**
```json
{
  "name": "MCP AI Tools Server",
  "version": "1.0.0",
  "description": "Model Context Protocol server hosting multiple AI tools",
  "endpoints": {
    "health": "GET /health",
    "listTools": "GET /tools",
    "toolInfo": "GET /tools/:toolName",
    "executeTool": "POST /tools/:toolName/execute"
  }
}
```

#### 2. Health Check
```
GET /health
```
Check server health status.

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T00:00:00.000Z",
  "uptime": 123.45
}
```

#### 3. List All Tools
```
GET /tools
```
Get a list of all available tools.

**Response:**
```json
{
  "count": 2,
  "tools": [
    {
      "name": "action_impact_model",
      "description": "Analyzes text to determine the potential impact of described actions",
      "version": "1.0.0"
    },
    {
      "name": "category_level_model",
      "description": "Categorizes text into hierarchical levels and identifies primary categories",
      "version": "1.0.0"
    }
  ]
}
```

#### 4. Get Tool Information
```
GET /tools/:toolName
```
Get detailed information about a specific tool.

**Example:**
```
GET /tools/action_impact_model
```

**Response:**
```json
{
  "metadata": {
    "name": "action_impact_model",
    "description": "Analyzes text to determine the potential impact of described actions",
    "version": "1.0.0",
    "inputSchema": "tool-input.schema.json",
    "outputSchema": "tool-output.schema.json"
  }
}
```

#### 5. Execute Tool
```
POST /tools/:toolName/execute
```
Execute a tool with provided input.

**Request Body:**
```json
{
  "text": "This is a critical task that needs urgent attention"
}
```

**Example:**
```bash
curl -X POST http://localhost:3000/tools/action_impact_model/execute \
  -H "Content-Type: application/json" \
  -d '{"text": "This is a critical task"}'
```

**Response (action_impact_model):**
```json
{
  "result": {
    "difficulty": 0.75,
    "lasting_effect": 0.82,
    "reach": 0.68,
    "effort_vs_outcome": 0.71,
    "impact_level": 0.79
  },
  "metadata": {
    "timestamp": "2024-01-01T00:00:00.000Z",
    "tool": "action_impact_model"
  }
}
```

**Response (category_level_model):**
```json
{
  "result": {
    "education": 0.12,
    "innovation": 0.65,
    "faith_spirituality": 0.03,
    "business": 0.45,
    "family_history": 0.08,
    "community": 0.18,
    "health": 0.09
  },
  "metadata": {
    "timestamp": "2024-01-01T00:00:00.000Z",
    "tool": "category_level_model"
  }
}
```

## üîß Available Tools

### 1. Action Impact Model
**Name:** `action_impact_model`

Analyzes text to determine the potential impact of described actions using the Impact Rating API.

**API Endpoint:** `https://ClergeF-Impact-Rating-API.hf.space/rate`

**Input:**
```json
{
  "text": "Your text here"
}
```

**Output:**
- `difficulty`: Numeric score indicating the difficulty of the action
- `lasting_effect`: Numeric score for the lasting effect of the action
- `reach`: Numeric score for the reach/scope of the action
- `effort_vs_outcome`: Numeric score comparing effort to outcome
- `impact_level`: Overall numeric impact level score

All scores are numeric values returned by the ML model.

### 2. Category Level Model
**Name:** `category_level_model`

Categorizes text using the Category Prediction API to return category confidence scores.

**API Endpoint:** `https://ClergeF-Catagorys-API.hf.space/predict`

**Input:**
```json
{
  "text": "Your text here"
}
```

**Output:**
- `education`: Confidence score for education category
- `innovation`: Confidence score for innovation category
- `faith_spirituality`: Confidence score for faith/spirituality category
- `business`: Confidence score for business category
- `family_history`: Confidence score for family/history category
- `community`: Confidence score for community category
- `health`: Confidence score for health category

All scores are numeric confidence values returned by the ML model.

## ‚ûï Adding New Tools

To add a new tool to the server:

1. Create a new file in the `/tools` directory (e.g., `my_tool.js`)
2. Implement the required exports:

```javascript
/**
 * Tool metadata
 */
export const toolMetadata = {
  name: 'my_tool',
  description: 'Description of what your tool does',
  version: '1.0.0',
  inputSchema: 'tool-input.schema.json',
  outputSchema: 'tool-output.schema.json'
};

/**
 * Tool execution function
 * @param {Object} input - The input object with 'text' property
 * @returns {Promise<Object>} The result object
 */
export async function execute(input) {
  const { text } = input;
  
  // Your tool logic here
  
  return {
    result: {
      // Your result data
    },
    metadata: {
      timestamp: new Date().toISOString(),
      tool: toolMetadata.name
    }
  };
}

export default { toolMetadata, execute };
```

3. Restart the server - your tool will be automatically loaded!

### Tool Requirements

- Must export `toolMetadata` object with `name`, `description`, and `version`
- Must export `execute` async function that accepts input and returns a result
- Input must conform to `tool-input.schema.json` (requires `text` property)
- Output must conform to `tool-output.schema.json` (requires `result` object)

## üåê Deployment

### Deploy to Vercel

1. Install Vercel CLI:
```bash
npm install -g vercel
```

2. Deploy:
```bash
vercel
```

3. Configure environment variables in Vercel dashboard if needed:
   - `PORT` (Vercel sets this automatically)
   - `NODE_ENV=production`

### Deploy to Render

1. Create a new Web Service on [Render](https://render.com)
2. Connect your repository
3. Configure:
   - **Build Command:** `npm install`
   - **Start Command:** `npm start`
   - **Environment Variables:**
     - `NODE_ENV=production`

### Deploy to Other Platforms

The server is compatible with any Node.js hosting platform. Ensure:
- Node.js 18+ is available
- The `PORT` environment variable is set (or use default 3000)
- Dependencies are installed with `npm install`
- Server starts with `npm start`

## ‚öôÔ∏è Configuration

Configuration is managed in `/config/server.config.js`. You can customize:

- **Port**: Server port (default: 3000)
- **Host**: Server host (default: 0.0.0.0)
- **CORS**: Cross-Origin Resource Sharing settings
- **Rate Limiting**: API rate limiting configuration
- **Logging**: Log level settings

Environment variables:
- `PORT`: Server port
- `HOST`: Server host
- `NODE_ENV`: Environment (development/production)
- `CORS_ORIGIN`: CORS origin setting
- `RATE_LIMIT_ENABLED`: Enable rate limiting (true/false)
- `LOG_LEVEL`: Logging level (info/debug/error)

## üß™ Testing

The project includes comprehensive tests for:
- Tool loading functionality
- Schema validation
- Individual tool execution

Run tests with:
```bash
npm test
```

## üîí Security

- Input validation using JSON schemas
- Error handling for all endpoints
- Graceful shutdown on SIGTERM
- CORS configuration for cross-origin requests

## üìù License

MIT

## ü§ù Contributing

Contributions are welcome! To contribute:

1. Fork the repository
2. Create a feature branch
3. Add your changes
4. Write tests for new functionality
5. Submit a pull request

## üìû Support

For issues, questions, or contributions, please open an issue in the repository.